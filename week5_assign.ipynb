{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHagJG6Wul4Y"
   },
   "source": [
    "This assignment serves three purposes:\n",
    "\n",
    "--> Introducing you to RandomForestClassifier\n",
    "--> Trying to implement Dense CNN model using the skills you gained till now\n",
    "\n",
    "This assingemnt might not contain a line to line explaination of the task to be performed. You got to start visiting the documentations or any example online to help you out with queries like syntax and parameters.\n",
    "\n",
    "The third and the most crucial purpose of all is helping you understand how to implement different models for the same task.\n",
    "Here, we have given you the task of hand-written digit classification on MNIST dataset, first using RandomForestClassifier and second using Dense CNN and if you wish, you could also try to implement this task from the model of previous assingment with of-course a little bit of tweaking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YuKiwK3Dn9Bq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKLusGinn9Bv",
    "outputId": "5cccbc1a-addc-415c-993e-7f4cfcb8628d"
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "# set path of dataset to mnist_path varaible and loadmat() it to mnist_raw\n",
    "\n",
    "mnist_raw=loadmat(\"mnist-original\")\n",
    "\n",
    "mnist ={ \"data\":mnist_raw[\"data\"].T,\"target\":mnist_raw[\"label\"][0],\n",
    "         \"COL_NAMES\":[\"label\",\"data\"],\"DESCR\": \"mldata.org dataset:mnist-original\",\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jk-UYMUzn9B1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:(70000, 784)\n",
      "Shape of Y:(70000,)\n"
     ]
    }
   ],
   "source": [
    "# store data in X and target in y\n",
    "X=mnist[\"data\"]\n",
    "y=mnist[\"target\"]\n",
    "\n",
    "\n",
    "#Our data is expected to has 70000 instances(rows) and 784 features(columns)\n",
    "\n",
    "print(\"Shape of X:\"+str(X.shape))\n",
    "print(\"Shape of Y:\"+str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ch8difi7n9B5"
   },
   "outputs": [],
   "source": [
    "#import matplotlib \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHTW7MPan9B9",
    "outputId": "973e9553-306c-42c3-c3a9-60ce59477c82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1667b5fcb48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick any example from z, rehshape it to 28x28 type and display it using matplot\n",
    "rndm=np.random.choice(range(y.shape[0]),1)\n",
    "plt.imshow(X[rndm].reshape(28,28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rL9RDX-n9CB"
   },
   "outputs": [],
   "source": [
    "# To randomize out data set we have to shuffle it\n",
    "#np.random.permutation() gives us an np.array of numbers in range given range\n",
    "#  reshuffle X and y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFG3ztPkn9CE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# we are dividing the data in 60,000 and 10,000 for training and testing\n",
    "X_train=X[:60000]\n",
    "X_test=X[60000:]\n",
    "y_train=y[:60000]\n",
    "y_test=y[60000:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "36J2MsdEn9CI",
    "outputId": "0129c70f-37cd-42e1-c08b-fdf22bee4fe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#create a rondom forest classifier with random state of 42 and fit your train varaibles \n",
    "\n",
    "model=RandomForestClassifier(random_state=42);\n",
    "model.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fw8rI-Bvn9CL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE in Train set  0.0\n",
      "Accuracy in Train set  1.0\n",
      "MAE in test set  0.1185\n",
      "Accuracy in Test set  0.9688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# predict your train X varariable and find mean_absolute error it should be around 0.00333\n",
    "y_pred=model.predict(X_train)\n",
    "err=mean_absolute_error(y_train,y_pred)\n",
    "print(\"MAE in Train set \",err)\n",
    "print(\"Accuracy in Train set \",accuracy_score(y_train,y_pred))\n",
    "# repeat the same for test X it should be around 0.205\n",
    "y_pred=model.predict(X_test)\n",
    "err=mean_absolute_error(y_test,y_pred)\n",
    "print(\"MAE in test set \",err)\n",
    "print(\"Accuracy in Test set \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSq2hH6Vn9CW"
   },
   "outputs": [],
   "source": [
    "# Now that RandonForest has been explored, we'll be implementing Dense CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehWGQ6VNn9Cb"
   },
   "outputs": [],
   "source": [
    "# First order of business is creating the model\n",
    "# for that purpose we've already imported the required things \n",
    "# your task is to use the above imported modules and whatever skills you have harnessed and build a model from scratch\n",
    "# JUST A REMINDER , WE TRIED TO INTRODUCE YOU ALL WITH MOST OF THE LIBRARIES WHICH WE USE ON A DAILY BASIS\n",
    "# ONE OF THEM IS KERAS USING WHICH YOU'LL IMPLEMENT THIS LAST ASSINGMENT \n",
    "# BUT DON'T WORRY THAT ITS NEW. THE CONCEPTS WHICH YOU ALL HAVE GAINED UPTIL NOW WILL ONLY BE USED \n",
    "# DON'T PANIC THAT YOU DON'T KNOW KERAS\n",
    "# JUST GIVE IT A TRY. CREATING A MODEL IS SIMILAR TO THAT IN PYTORCH.\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization,Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "# keras initializer\n",
    "X1_train=X_train.reshape(60000,28,28)\n",
    "X1_test=X_test.reshape(10000,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0P5nGgan9Cg"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6zsw6k7kn9Cj"
   },
   "outputs": [],
   "source": [
    "# after creating the model compile it with proper optimizer and loss function \n",
    "# You can refer to any keras model training for your reference \n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsNYrB4En9Cm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 244us/sample - loss: 2.4160 - accuracy: 0.8565\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.3941 - accuracy: 0.9084\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 177us/sample - loss: 0.2882 - accuracy: 0.9272\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.2480 - accuracy: 0.9374\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 11s 177us/sample - loss: 0.2207 - accuracy: 0.9452\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 0.2200 - accuracy: 0.9469\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 0.2025 - accuracy: 0.9510\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 11s 182us/sample - loss: 0.1904 - accuracy: 0.9528\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 185us/sample - loss: 0.1899 - accuracy: 0.9545\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 0.1843 - accuracy: 0.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16602e7af08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit your train datasets\n",
    "model.fit(X1_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3iZnY1S8n9Cq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.2638 - accuracy: 0.9508\n",
      "\n",
      "Test accuracy: 0.9508\n",
      "\n",
      "Test loss: 0.2637669875119915\n"
     ]
    }
   ],
   "source": [
    "# After fitting try your model with test dataset\n",
    "# see the accuracy\n",
    "test_loss, test_acc = model.evaluate(X1_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\nTest loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same',input_shape=(28,28,1)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 232s 4ms/sample - loss: 0.2905 - accuracy: 0.9379\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 225s 4ms/sample - loss: 0.0575 - accuracy: 0.9823\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 215s 4ms/sample - loss: 0.0438 - accuracy: 0.9867\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 218s 4ms/sample - loss: 0.0359 - accuracy: 0.9886\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 236s 4ms/sample - loss: 0.0323 - accuracy: 0.9898\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 263s 4ms/sample - loss: 0.0297 - accuracy: 0.9907\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 229s 4ms/sample - loss: 0.0285 - accuracy: 0.9906\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 229s 4ms/sample - loss: 0.0233 - accuracy: 0.9928\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 213s 4ms/sample - loss: 0.0233 - accuracy: 0.9924\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 227s 4ms/sample - loss: 0.0185 - accuracy: 0.9942\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 221s 4ms/sample - loss: 0.0205 - accuracy: 0.9939\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 229s 4ms/sample - loss: 0.0171 - accuracy: 0.9948\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 241s 4ms/sample - loss: 0.0155 - accuracy: 0.9950\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 240s 4ms/sample - loss: 0.0178 - accuracy: 0.9945\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 241s 4ms/sample - loss: 0.0124 - accuracy: 0.9964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16603193a48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X1_train.reshape(60000,28,28,1), y_train,epochs=15, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 15s - loss: 0.0537 - accuracy: 0.9896\n",
      "\n",
      "Test accuracy: 0.9896\n",
      "\n",
      "Test loss: 0.053672715060734365\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X1_test.reshape(10000,28,28,1),  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\nTest loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Src3IB64n9C0"
   },
   "outputs": [],
   "source": [
    "# Understand how and where to use which model and jot down your observations in a text file in the github repository."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
